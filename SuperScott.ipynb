{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import *\n",
    "import scipy.stats as stats\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import time\n",
    "import tqdm\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wheteher GPU is being used\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device, torch.cuda.get_device_name(0))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device= torch.device(\"cpu\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution - Batch Normalization - Leaky block\n",
    "class CBL(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, kernel_size, stride, padding):\n",
    "        super(CBL, self).__init__()\n",
    "        \n",
    "        # Attributes\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Sequential block\n",
    "        self.cbl = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, channels_out, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(channels_out),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.cbl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution - Batch Normalization - Mish block\n",
    "class CBM(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, kernel_size, stride, padding):\n",
    "        super(CBM, self).__init__()\n",
    "        \n",
    "        # Attributes\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Sequential block\n",
    "        self.cbm = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, channels_out, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(channels_out),\n",
    "            nn.Mish(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.cbm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution - Batch Normalization - ReLU block\n",
    "class CBR(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, kernel_size, stride, padding):\n",
    "        super(CBR, self).__init__()\n",
    "        \n",
    "        # Attributes\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self. padding = padding\n",
    "        \n",
    "        # Sequential block\n",
    "        self.cbr = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, channels_out, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(channels_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.cbr(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResCBR \n",
    "class ResCBR(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, kernel_size, stride, padding):\n",
    "        super(ResCBR, self).__init__()\n",
    "        \n",
    "        # Attributes\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.res_padding = (kernel_size - 1) // 2\n",
    "        \n",
    "        # Sequential block\n",
    "        self.seq_block = nn.Sequential(\n",
    "            CBR(channels_in, channels_in, kernel_size=kernel_size, stride=1, padding=self.res_padding),\n",
    "            CBR(channels_in, channels_in, kernel_size=kernel_size, stride=1, padding=self.res_padding),\n",
    "        )\n",
    "        self.cbr = CBR(channels_in, channels_out, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.seq_block(x)\n",
    "        y = self.cbr(h + x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScottCBR(nn.Module):\n",
    "    def __init__(self, classes: int = 2):\n",
    "        super(ScottCBR, self).__init__()\n",
    "        \n",
    "        # Blocks\n",
    "        self.block1 = nn.Sequential(\n",
    "            CBR(3, 8, kernel_size=3, stride=1, padding=0),\n",
    "            CBR(8, 7, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            CBR(7, 6, kernel_size=3, stride=1, padding=0),\n",
    "            CBR(6, 5, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            CBR(5, 4, kernel_size=3, stride=1, padding=0),\n",
    "            CBR(4, 3, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear((19 * 19 * 3), 512),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        \n",
    "        block3 = block3.reshape(block3.size(0), -1)\n",
    "        pred = self.classification(block3)\n",
    "        \n",
    "        return torch.softmax(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScottCBL(nn.Module):\n",
    "    def __init__(self, classes: int = 2):\n",
    "        super(ScottCBL, self).__init__()\n",
    "    \n",
    "        # Blocks\n",
    "        self.block1 = nn.Sequential(\n",
    "            CBL(3, 8, kernel_size=3, stride=1, padding=0),\n",
    "            CBL(8, 7, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            CBL(7, 6, kernel_size=3, stride=1, padding=0),\n",
    "            CBL(6, 5, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            CBL(5, 4, kernel_size=3, stride=1, padding=0),\n",
    "            CBL(4, 3, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear((19 * 19 * 3), 512),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        \n",
    "        block3 = block3.reshape(block3.size(0), -1)\n",
    "        pred = self.classification(block3)\n",
    "        \n",
    "        return torch.softmax(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScottCBM(nn.Module):\n",
    "    def __init__(self, classes: int = 2):\n",
    "        super(ScottCBM, self).__init__()\n",
    "        \n",
    "        # Blocks\n",
    "        self.block1 = nn.Sequential(\n",
    "            CBM(3, 8, kernel_size=3, stride=1, padding=0),\n",
    "            CBM(8, 7, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            CBM(7, 6, kernel_size=3, stride=1, padding=0),\n",
    "            CBM(6, 5, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            CBM(5, 4, kernel_size=3, stride=1, padding=0),\n",
    "            CBM(4, 3, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear((19 * 19 * 3), 512),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        \n",
    "        block3 = block3.reshape(block3.size(0), -1)\n",
    "        pred = self.classification(block3)\n",
    "        \n",
    "        return torch.softmax(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScottRes(nn.Module):\n",
    "    def __init__(self, classes: int = 2):\n",
    "        super(ScottRes, self).__init__()\n",
    "        \n",
    "        # Blocks\n",
    "        self.block1 = nn.Sequential(\n",
    "            ResCBR(3, 8, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(8, 7, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            ResCBR(7, 6, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(6, 5, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            ResCBR(5, 4, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(4, 3, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear((19 * 19 * 3), 512),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        \n",
    "        block3 = block3.reshape(block3.size(0), -1)\n",
    "        pred = self.classification(block3)\n",
    "        \n",
    "        return torch.softmax(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScottDonPool(nn.Module):\n",
    "    def __init__(self, classes: int = 2):\n",
    "        super(ScottDonPool, self).__init__()\n",
    "        \n",
    "        # Blocks\n",
    "        self.block1 = nn.Sequential(\n",
    "            ResCBR(3, 8, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(8, 7, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(7, 7, kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            ResCBR(7, 6, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(6, 5, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(5, 5, kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            ResCBR(5, 4, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(4, 3, kernel_size=3, stride=1, padding=0),\n",
    "            ResCBR(3, 3, kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear((19 * 19 * 3), 512),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        \n",
    "        block3 = block3.reshape(block3.size(0), -1)\n",
    "        pred = self.classification(block3)\n",
    "        \n",
    "        return torch.softmax(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scott(nn.Module):\n",
    "    def __init__(self, classes: int = 2):\n",
    "        super(Scott, self).__init__()\n",
    "        \n",
    "        # Blocks\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 7, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(7, 6, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(6, 5, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(5, 4, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 3, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear((19 * 19 * 3), 512),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        \n",
    "        block3 = block3.reshape(block3.size(0), -1)\n",
    "        pred = self.classification(block3)\n",
    "        \n",
    "        return torch.softmax(pred, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoffeeDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.values_frame = pd.read_csv(csv_file, header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.values_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir, \n",
    "                                self.values_frame.iloc[idx, 0])\n",
    "        image = cv.imread(img_name)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        values = self.values_frame.iloc[idx, 1:]\n",
    "        values = np.array(values)\n",
    "        sample = {'image': image, 'values':values}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize image\n",
    "class Resize(object):\n",
    "    def __init__(self, size: int = 180):\n",
    "        self.size = size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, values = sample['image'], sample['values']\n",
    "        h, w, _ = image.shape\n",
    "        idx_ax = np.argmin([h, w])\n",
    "        pad = abs((np.min([h, w]) - np.max([h, w]))//2)\n",
    "        top, lat = 0, 0\n",
    "        if idx_ax == 0: \n",
    "            top = pad\n",
    "        else:\n",
    "            lat = pad\n",
    "        image = cv.copyMakeBorder(image, top, top, lat, lat,  borderType=cv.BORDER_REPLICATE)\n",
    "        image = cv.resize(image, (self.size, self.size))\n",
    "        return {'image': image, \n",
    "                'values': values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, values = sample['image'], sample['values']\n",
    "        image = torch.FloatTensor(image) / 255.\n",
    "        return {'image': image, \n",
    "                'values': torch.from_numpy(values.astype('float'))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "train_ratio = 0.8\n",
    "dataset = CoffeeDataset('Dataset_Beans.csv', root_dir='.', \n",
    "                              transform=transforms.Compose([Resize(180), ToTensor()]))\n",
    "train_size = int(len(dataset) * train_ratio)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(train_loader):\n",
    "    inputs, values = sample['image'], sample['values']\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    for j in range(len(ax)):\n",
    "        ax[j].imshow(inputs[j].numpy(), cmap='gray')\n",
    "        ax[j].set_xticks([])\n",
    "        ax[j].set_yticks([])\n",
    "        ax[j].set_title(values[j].numpy().astype(int)[0], fontsize=16)\n",
    "    break\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classification model\n",
    "model = ScottDonPool().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "summary(model, (3, 180, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for CNN\n",
    "epochs = 100\n",
    "pbar = tqdm.tqdm(range(1, epochs+1))\n",
    "loss_array = []\n",
    "torch.cuda.empty_cache()\n",
    "model.train()\n",
    "for e in pbar:\n",
    "    batch_count = 0\n",
    "    running_loss = 0.\n",
    "    epoch_loss = 0.\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        inputs, values = sample['image'], sample['values']\n",
    "        inputs = inputs.type(torch.FloatTensor).permute(0, -1, 1, 2).to(device)\n",
    "        values = values.type(torch.LongTensor).to(device).flatten()\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_func(predictions, values)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        batch_count += 1\n",
    "    batch_loss = running_loss / batch_count\n",
    "    loss_array.append(batch_loss)\n",
    "    pbar.set_description('Epoch {}, Loss {:,.3f}'.format(e, loss_array[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(loss_array)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "torch.save(model.state_dict(), 'SuperScott.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for CNN\n",
    "epochs = 100\n",
    "pbar = tqdm.tqdm(range(1, epochs+1))\n",
    "will_loss_array = []\n",
    "torch.cuda.empty_cache()\n",
    "will_model.train()\n",
    "for e in pbar:\n",
    "    batch_count = 0\n",
    "    running_loss = 0.\n",
    "    epoch_loss = 0.\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        inputs, values = sample['image'], sample['values']\n",
    "        inputs = inputs.type(torch.FloatTensor).permute(0, -1, 1, 2).to(device)\n",
    "        values = values.type(torch.LongTensor).to(device).flatten()\n",
    "        predictions = will_model(inputs)\n",
    "        loss = will_loss_func(predictions, values)\n",
    "        will_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        will_optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        batch_count += 1\n",
    "    batch_loss = running_loss / batch_count\n",
    "    will_loss_array.append(batch_loss)\n",
    "    pbar.set_description('Epoch {}, Loss {:,.3f}'.format(e, will_loss_array[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(will_loss_array)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(will_model.state_dict(), 'Coffee_Defects_Will_2021_12_02.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('Coffee_Defects_2021_11_30-2.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "model.eval()\n",
    "reals = []\n",
    "predictions = []\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        inputs, values = sample['image'], sample['values']\n",
    "        inputs = inputs.type(torch.FloatTensor).permute(0, -1, 1, 2).to(device)\n",
    "        values = values.numpy().flatten()\n",
    "        t0 = time.time()\n",
    "        pred = model(inputs).cpu().numpy()\n",
    "        pred = np.argmax(pred, axis=1).flatten()\n",
    "        times.append(time.time() - t0)\n",
    "        predictions.append(pred)\n",
    "        reals.append(values)\n",
    "cf_matrix = confusion_matrix(reals, predictions, normalize=None)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='.2f', cmap='YlOrBr', \n",
    "            cbar=False, annot_kws={'fontsize': 14})\n",
    "print('Average time {:,.3f}ms'.format(np.mean(times) * 1000.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Test model\n",
    "model.eval()\n",
    "reals = []\n",
    "predictions = []\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        inputs, values = sample['image'], sample['values']\n",
    "        inputs = inputs.type(torch.FloatTensor).permute(0, -1, 1, 2).to(device)\n",
    "        values = values.numpy().flatten()\n",
    "        t0 = time.time()\n",
    "        pred = model(inputs).cpu().numpy()\n",
    "        pred = np.argmax(pred, axis=1).flatten()\n",
    "        times.append(time.time() - t0)\n",
    "        predictions.append(pred)\n",
    "        reals.append(values)\n",
    "cf_matrix = confusion_matrix(reals, predictions, normalize=None)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='.2f', cmap='YlOrBr', \n",
    "            cbar=False, annot_kws={'fontsize': 14})\n",
    "print('Average time {:,.3f}ms'.format(np.mean(times) * 1000.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Test model\n",
    "will_model.eval()\n",
    "reals = []\n",
    "predictions = []\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        inputs, values = sample['image'], sample['values']\n",
    "        inputs = inputs.type(torch.FloatTensor).permute(0, -1, 1, 2).to(device)\n",
    "        values = values.numpy().flatten()\n",
    "        t0 = time.time()\n",
    "        pred = will_model(inputs).cpu().numpy()\n",
    "        pred = np.argmax(pred, axis=1).flatten()\n",
    "        times.append(time.time() - t0)\n",
    "        predictions.append(pred)\n",
    "        reals.append(values)\n",
    "cf_matrix = confusion_matrix(reals, predictions, normalize=None)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap='YlOrBr', \n",
    "            cbar=False, annot_kws={'fontsize': 14})\n",
    "print('Average time {:,.3f}ms'.format(np.mean(times) * 1000.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(reals, predictions, normalize='true')\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='.2%', cmap='YlOrBr', \n",
    "            cbar=False, annot_kws={'fontsize': 14})\n",
    "print('Average time {:,.3f}ms'.format(np.mean(times) * 1000.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
